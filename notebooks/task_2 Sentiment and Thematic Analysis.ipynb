{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b99fc74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All libraries installed and imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# required packages\n",
    "os.system(\"pip install pandas scikit-learn spacy transformers vaderSentiment\")\n",
    "\n",
    "# Download spaCy model\n",
    "os.system(\"python -m spacy download en_core_web_sm\")\n",
    "\n",
    "# Verify imports\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import spacy\n",
    "from transformers import pipeline\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "print(\"All libraries installed and imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cbfc922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading your bank reviews dataset...\n",
      "Success! Loaded 475 reviews.\n",
      "\n",
      "Checking for missing values in the dataset:\n",
      "review_id      0\n",
      "review_text    0\n",
      "bank           0\n",
      "rating         0\n",
      "dtype: int64\n",
      "\n",
      "Converted all review text to lowercase for consistency.\n",
      "\n",
      "Here's a peek at the first few rows:\n",
      "   review_id          review_text                         bank  rating\n",
      "0          1                dedeb  Commercial Bank of Ethiopia       5\n",
      "1          2                 good  Commercial Bank of Ethiopia       5\n",
      "2          3                 good  Commercial Bank of Ethiopia       5\n",
      "3          4            very niec  Commercial Bank of Ethiopia       5\n",
      "4          5  best app of finance  Commercial Bank of Ethiopia       5\n",
      "\n",
      "All done! Preprocessed data saved to C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\preprocessed_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set the file path to your dataset\n",
    "file_path = r\"C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\bank_reviews.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading your bank reviews dataset...\")\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Success! Loaded {len(df)} reviews.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Oops! Couldn't find 'bank_reviews.csv' at {file_path}. Please check the file path and try again.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Something went wrong while loading the file: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Create a review_id column (since it's required but missing)\n",
    "df['review_id'] = df.index + 1  # Simple ID based on row number\n",
    "\n",
    "# Rename 'review' column to 'review_text' for consistency\n",
    "df = df.rename(columns={'review': 'review_text'})\n",
    "\n",
    "# Check for required columns\n",
    "expected_columns = ['review_id', 'review_text', 'bank', 'rating']\n",
    "if not all(col in df.columns for col in expected_columns):\n",
    "    print(f\"Error: The dataset needs these columns: {expected_columns}. Please check your data.\")\n",
    "    exit()\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nChecking for missing values in the dataset:\")\n",
    "print(df[expected_columns].isnull().sum())\n",
    "\n",
    "# Drop rows with missing review_text\n",
    "initial_rows = len(df)\n",
    "df = df.dropna(subset=['review_text'])\n",
    "if len(df) < initial_rows:\n",
    "    print(f\"Dropped {initial_rows - len(df)} rows with missing review text.\")\n",
    "\n",
    "# Convert review_text to lowercase\n",
    "df['review_text'] = df['review_text'].astype(str).str.lower()\n",
    "print(\"\\nConverted all review text to lowercase for consistency.\")\n",
    "\n",
    "# Show a preview of the preprocessed data\n",
    "print(\"\\nHere's a peek at the first few rows:\")\n",
    "print(df[['review_id', 'review_text', 'bank', 'rating']].head())\n",
    "\n",
    "# Save the preprocessed data\n",
    "output_path = r\"C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\preprocessed_reviews.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"\\nAll done! Preprocessed data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497e1404",
   "metadata": {},
   "source": [
    "# sentiment Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "538e4942",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed reviews...\n",
      "Success! Loaded 475 reviews.\n",
      "Loading DistilBERT model (this may take a moment)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "c:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\HP\\.cache\\huggingface\\hub\\models--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing sentiments with DistilBERT...\n",
      "\n",
      "Here's a peek at the reviews with sentiment:\n",
      "   review_id          review_text                         bank  rating  \\\n",
      "0          1                dedeb  Commercial Bank of Ethiopia       5   \n",
      "1          2                 good  Commercial Bank of Ethiopia       5   \n",
      "2          3                 good  Commercial Bank of Ethiopia       5   \n",
      "3          4            very niec  Commercial Bank of Ethiopia       5   \n",
      "4          5  best app of finance  Commercial Bank of Ethiopia       5   \n",
      "\n",
      "  sentiment_label  sentiment_score  \n",
      "0        negative         0.997484  \n",
      "1        positive         0.999816  \n",
      "2        positive         0.999816  \n",
      "3         neutral         0.519262  \n",
      "4        positive         0.999650  \n",
      "\n",
      "All done! Reviews with sentiment saved to C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\reviews_with_sentiment.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Set file paths\n",
    "input_path = r\"C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\preprocessed_reviews.csv\"\n",
    "output_path = r\"C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\reviews_with_sentiment.csv\"\n",
    "\n",
    "# Load the preprocessed dataset\n",
    "print(\"Loading preprocessed reviews...\")\n",
    "try:\n",
    "    df = pd.read_csv(input_path)\n",
    "    print(f\"Success! Loaded {len(df)} reviews.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Oops! Couldn't find 'preprocessed_reviews.csv' at {input_path}. Please check the file.\")\n",
    "    exit()\n",
    "\n",
    "# Initialize DistilBERT sentiment model\n",
    "print(\"Loading DistilBERT model (this may take a moment)...\")\n",
    "try:\n",
    "    distilbert = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading DistilBERT model: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Compute sentiment for each review\n",
    "def get_distilbert_sentiment(text):\n",
    "    try:\n",
    "        # Truncate text to 512 tokens (DistilBERT's max length)\n",
    "        result = distilbert(text[:512])[0]\n",
    "        label = result['label'].lower()  # 'POSITIVE' or 'NEGATIVE'\n",
    "        score = result['score']\n",
    "        # Convert to task's required labels (positive, negative, neutral)\n",
    "        if label == 'positive' and score >= 0.6:\n",
    "            return 'positive', score\n",
    "        elif label == 'negative' and score >= 0.6:\n",
    "            return 'negative', score\n",
    "        else:\n",
    "            return 'neutral', score\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing review: {e}\")\n",
    "        return 'neutral', 0.5  # Default for errors\n",
    "\n",
    "print(\"Analyzing sentiments with DistilBERT...\")\n",
    "df[['sentiment_label', 'sentiment_score']] = df['review_text'].apply(get_distilbert_sentiment).apply(pd.Series)\n",
    "\n",
    "# Show a preview of the results\n",
    "print(\"\\nHere's a peek at the reviews with sentiment:\")\n",
    "print(df[['review_id', 'review_text', 'bank', 'rating', 'sentiment_label', 'sentiment_score']].head())\n",
    "\n",
    "# Save the results\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"\\nAll done! Reviews with sentiment saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294be347",
   "metadata": {},
   "source": [
    "# Sentiment aggregation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f83157b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment distribution:\n",
      "sentiment_label\n",
      "positive    243\n",
      "negative    228\n",
      "neutral       4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sentiment by rating:\n",
      "rating  sentiment_label\n",
      "1       negative           122\n",
      "        positive            11\n",
      "2       negative            20\n",
      "        neutral              1\n",
      "        positive             1\n",
      "3       positive            17\n",
      "        negative            15\n",
      "4       positive            16\n",
      "        negative            11\n",
      "        neutral              1\n",
      "5       positive           198\n",
      "        negative            60\n",
      "        neutral              2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSentiment distribution:\")\n",
    "print(df['sentiment_label'].value_counts())\n",
    "print(\"\\nSentiment by rating:\")\n",
    "print(df.groupby('rating')['sentiment_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2d0532a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reviews with sentiment...\n",
      "Success! Loaded 475 reviews.\n",
      "\n",
      "Calculating average sentiment scores by bank and rating...\n",
      "\n",
      "Sentiment aggregation results:\n",
      "                           bank  rating  mean_sentiment_score  review_count\n",
      "0             Bank of Abyssinia       1              0.983562            71\n",
      "1             Bank of Abyssinia       2              0.911954             8\n",
      "2             Bank of Abyssinia       3              0.955327            12\n",
      "3             Bank of Abyssinia       4              0.932922             5\n",
      "4             Bank of Abyssinia       5              0.966467            65\n",
      "5   Commercial Bank of Ethiopia       1              0.945291            32\n",
      "6   Commercial Bank of Ethiopia       2              0.998126             6\n",
      "7   Commercial Bank of Ethiopia       3              0.998774             5\n",
      "8   Commercial Bank of Ethiopia       4              0.957053            15\n",
      "9   Commercial Bank of Ethiopia       5              0.966501           102\n",
      "10                  Dashen Bank       1              0.983211            30\n",
      "11                  Dashen Bank       2              0.967532             8\n",
      "12                  Dashen Bank       3              0.956976            15\n",
      "13                  Dashen Bank       4              0.986274             8\n",
      "14                  Dashen Bank       5              0.962612            93\n",
      "\n",
      "Aggregation saved to C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\sentiment_aggregation.csv\n",
      "Main dataset unchanged, saved back to C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\reviews_with_sentiment.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set file paths\n",
    "input_path = r\"C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\reviews_with_sentiment.csv\"\n",
    "output_agg_path = r\"C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\sentiment_aggregation.csv\"\n",
    "\n",
    "# Load the dataset with sentiments\n",
    "print(\"Loading reviews with sentiment...\")\n",
    "try:\n",
    "    df = pd.read_csv(input_path)\n",
    "    print(f\"Success! Loaded {len(df)} reviews.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Oops! Couldn't find 'reviews_with_sentiment.csv' at {input_path}. Please check the file.\")\n",
    "    exit()\n",
    "\n",
    "# Aggregate sentiment scores by bank and rating\n",
    "print(\"\\nCalculating average sentiment scores by bank and rating...\")\n",
    "sentiment_agg = df.groupby(['bank', 'rating']).agg(\n",
    "    mean_sentiment_score=('sentiment_score', 'mean'),\n",
    "    review_count=('sentiment_score', 'count')\n",
    ").reset_index()\n",
    "\n",
    "# Show the aggregated results\n",
    "print(\"\\nSentiment aggregation results:\")\n",
    "print(sentiment_agg)\n",
    "\n",
    "# Save the aggregated results\n",
    "sentiment_agg.to_csv(output_agg_path, index=False)\n",
    "print(f\"\\nAggregation saved to {output_agg_path}\")\n",
    "\n",
    "# Save the main DataFrame (unchanged, for consistency)\n",
    "df.to_csv(input_path, index=False)\n",
    "print(f\"Main dataset unchanged, saved back to {input_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ea52c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall sentiment distribution:\n",
      "sentiment_label\n",
      "positive    243\n",
      "negative    228\n",
      "neutral       4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOverall sentiment distribution:\")\n",
    "print(df['sentiment_label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58265a8",
   "metadata": {},
   "source": [
    "# Keyword Extraction with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f587995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reviews with sentiment...\n",
      "Success! Loaded 475 reviews.\n",
      "\n",
      "Extracting keywords and phrases with TF-IDF...\n",
      "\n",
      "Top keywords/phrases for each bank:\n",
      "\n",
      "Commercial Bank of Ethiopia:\n",
      "['access' 'add' 'amazing' 'app' 'application' 'apps' 'bad' 'bank'\n",
      " 'banking' 'banking app' 'best' 'best app' 'cbe' 'developer' 'doesnt'\n",
      " 'don' 'easy' 'easy use' 'fast' 'fix']\n",
      "\n",
      "Bank of Abyssinia:\n",
      "['abyssinia' 'access' 'account' 'amazing' 'app' 'app crashes'\n",
      " 'application' 'apps' 'automatically' 'bank' 'banking' 'banking app'\n",
      " 'best' 'better' 'boa' 'bug' 'crashes' 'developer' 'developer options'\n",
      " 'doesn']\n",
      "\n",
      "Dashen Bank:\n",
      "['account' 'amole' 'android' 'apk' 'app' 'app good' 'application' 'bad'\n",
      " 'bank' 'banking' 'banking app' 'best' 'dashen' 'dashen bank' 'doesn'\n",
      " 'doesn work' 'don' 'easy' 'easy use' 'ethiopia']\n",
      "\n",
      "Here's a peek at the reviews with keywords:\n",
      "   review_id          review_text                         bank tfidf_keywords\n",
      "0          1                dedeb  Commercial Bank of Ethiopia         access\n",
      "1          2                 good  Commercial Bank of Ethiopia           good\n",
      "2          3                 good  Commercial Bank of Ethiopia           good\n",
      "3          4            very niec  Commercial Bank of Ethiopia         access\n",
      "4          5  best app of finance  Commercial Bank of Ethiopia       best app\n",
      "\n",
      "All done! Reviews with keywords saved to C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\reviews_with_keywords.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Set file paths\n",
    "input_path = r\"C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\reviews_with_sentiment.csv\"\n",
    "output_path = r\"C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\reviews_with_keywords.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading reviews with sentiment...\")\n",
    "try:\n",
    "    df = pd.read_csv(input_path)\n",
    "    print(f\"Success! Loaded {len(df)} reviews.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Oops! Couldn't find 'reviews_with_sentiment.csv' at {input_path}. Please check if Step 4 completed.\")\n",
    "    exit()\n",
    "\n",
    "# Initialize TF-IDF vectorizer (unigrams and bigrams)\n",
    "print(\"\\nExtracting keywords and phrases with TF-IDF...\")\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=50, ngram_range=(1, 2))\n",
    "\n",
    "# Function to get top keyword per review\n",
    "def get_top_keyword(review, tfidf_matrix, feature_names):\n",
    "    try:\n",
    "        row = tfidf_matrix[df[df['review_text'] == review].index[0]].toarray()[0]\n",
    "        top_idx = row.argmax()\n",
    "        return feature_names[top_idx]\n",
    "    except:\n",
    "        return 'none'  # Fallback for empty/short reviews\n",
    "\n",
    "# Extract keywords for all reviews\n",
    "tfidf_matrix = tfidf.fit_transform(df['review_text'])\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "df['tfidf_keywords'] = df['review_text'].apply(lambda x: get_top_keyword(x, tfidf_matrix, feature_names))\n",
    "\n",
    "# Extract bank-specific keywords\n",
    "print(\"\\nTop keywords/phrases for each bank:\")\n",
    "for bank in df['bank'].unique():\n",
    "    bank_reviews = df[df['bank'] == bank]['review_text']\n",
    "    if len(bank_reviews) > 0:\n",
    "        tfidf_matrix_bank = tfidf.fit_transform(bank_reviews)\n",
    "        bank_keywords = tfidf.get_feature_names_out()\n",
    "        print(f\"\\n{bank}:\")\n",
    "        print(bank_keywords[:20])  # Top 20 keywords/n-grams\n",
    "\n",
    "# Show a preview of the results\n",
    "print(\"\\nHere's a peek at the reviews with keywords:\")\n",
    "print(df[['review_id', 'review_text', 'bank', 'tfidf_keywords']].head())\n",
    "\n",
    "# Save the results\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"\\nAll done! Reviews with keywords saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2a9f57",
   "metadata": {},
   "source": [
    "# Reviews with spaCy keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c170465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reviews with TF-IDF keywords...\n",
      "Success! Loaded 475 reviews.\n",
      "\n",
      "Loading spaCy model...\n",
      "\n",
      "Extracting noun phrases and tokens with spaCy...\n",
      "\n",
      "Top noun phrases for each bank:\n",
      "\n",
      "Commercial Bank of Ethiopia:\n",
      "[('best app', 3), ('old transactions', 2), ('funds', 2), ('cbe', 2), ('good job', 2), ('time', 2), ('good app', 2), ('dedeb', 1), ('finance', 1), ('yetemeta', 1)]\n",
      "\n",
      "Bank of Abyssinia:\n",
      "[('money', 7), ('boa', 6), ('developer options', 4), ('bank', 4), ('mobile banking', 4), ('app', 4), ('cbe', 3), ('choice', 2), ('time', 2), ('worst app', 2)]\n",
      "\n",
      "Dashen Bank:\n",
      "[('good app', 4), ('ethiopia', 4), ('amole', 3), ('security', 3), ('update', 3), ('nice app', 3), ('long time', 3), ('telebirr', 2), ('self', 2), ('excellent app', 2)]\n",
      "\n",
      "Here's a peek at the reviews with spaCy keywords:\n",
      "   review_id          review_text                         bank  \\\n",
      "0          1                dedeb  Commercial Bank of Ethiopia   \n",
      "1          2                 good  Commercial Bank of Ethiopia   \n",
      "2          3                 good  Commercial Bank of Ethiopia   \n",
      "3          4            very niec  Commercial Bank of Ethiopia   \n",
      "4          5  best app of finance  Commercial Bank of Ethiopia   \n",
      "\n",
      "          noun_phrases                tokens  \n",
      "0              [dedeb]               [dedeb]  \n",
      "1                   []                [good]  \n",
      "2                   []                [good]  \n",
      "3                   []                [niec]  \n",
      "4  [best app, finance]  [good, app, finance]  \n",
      "\n",
      "All done! Reviews with spaCy keywords saved to C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\reviews_with_spacy_keywords.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "# Set file paths\n",
    "input_path = r\"C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\reviews_with_keywords.csv\"\n",
    "output_path = r\"C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\reviews_with_spacy_keywords.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading reviews with TF-IDF keywords...\")\n",
    "try:\n",
    "    df = pd.read_csv(input_path)\n",
    "    print(f\"Success! Loaded {len(df)} reviews.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Oops! Couldn't find 'reviews_with_keywords.csv' at {input_path}. Please check if Step 5 completed.\")\n",
    "    exit()\n",
    "\n",
    "# Load spaCy model\n",
    "print(\"\\nLoading spaCy model...\")\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading spaCy model: {e}. Did you run 'python -m spacy download en_core_web_sm'?\")\n",
    "    exit()\n",
    "\n",
    "# Extract noun phrases and lemmatized tokens\n",
    "def extract_spacy_keywords(text):\n",
    "    try:\n",
    "        doc = nlp(text)\n",
    "        # Noun phrases (non-stop words)\n",
    "        noun_phrases = [chunk.text.lower() for chunk in doc.noun_chunks if not any(token.is_stop for token in chunk)]\n",
    "        # Lemmatized tokens (non-stop words, alphabetic only)\n",
    "        tokens = [token.lemma_.lower() for token in doc if token.is_alpha and not token.is_stop]\n",
    "        return noun_phrases, tokens\n",
    "    except:\n",
    "        return [], []  # Fallback for errors or empty text\n",
    "\n",
    "print(\"\\nExtracting noun phrases and tokens with spaCy...\")\n",
    "df[['noun_phrases', 'tokens']] = df['review_text'].apply(extract_spacy_keywords).apply(pd.Series)\n",
    "\n",
    "# Extract top noun phrases per bank\n",
    "print(\"\\nTop noun phrases for each bank:\")\n",
    "for bank in df['bank'].unique():\n",
    "    bank_phrases = df[df['bank'] == bank]['noun_phrases'].explode().dropna()\n",
    "    if len(bank_phrases) > 0:\n",
    "        top_phrases = Counter(bank_phrases).most_common(10)\n",
    "        print(f\"\\n{bank}:\")\n",
    "        print(top_phrases)\n",
    "\n",
    "# Show a preview of the results\n",
    "print(\"\\nHere's a peek at the reviews with spaCy keywords:\")\n",
    "print(df[['review_id', 'review_text', 'bank', 'noun_phrases', 'tokens']].head())\n",
    "\n",
    "# Save the results\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"\\nAll done! Reviews with spaCy keywords saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a060df98",
   "metadata": {},
   "source": [
    "# Thematic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208f4a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reviews with spaCy keywords...\n",
      "Success! Loaded 475 reviews.\n",
      "\n",
      "Filtering out short reviews (less than 3 words)...\n",
      "Kept 341 reviews after filtering out 134 short reviews.\n",
      "\n",
      "Assigning themes to reviews...\n",
      "\n",
      "Theme distribution by bank:\n",
      "\n",
      "Commercial Bank of Ethiopia:\n",
      "theme\n",
      "Other                    78\n",
      "App Performance           8\n",
      "Customer Support          8\n",
      "Account Access Issues     6\n",
      "Positive Feedback         5\n",
      "Feature Requests          1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Bank of Abyssinia:\n",
      "theme\n",
      "Other                    77\n",
      "App Performance          18\n",
      "Feature Requests          7\n",
      "Account Access Issues     6\n",
      "Positive Feedback         5\n",
      "Customer Support          5\n",
      "User Interface            2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Dashen Bank:\n",
      "theme\n",
      "Other                    78\n",
      "App Performance          12\n",
      "User Interface            7\n",
      "Customer Support          5\n",
      "Feature Requests          5\n",
      "Positive Feedback         4\n",
      "Account Access Issues     4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Here's a peek at the reviews with themes:\n",
      "    review_id                                        review_text  \\\n",
      "4           5                                best app of finance   \n",
      "6           7                               engida kebede fetera   \n",
      "7           8                                   it is not safety   \n",
      "9          10  it is like a childish app make it better the w...   \n",
      "10         11  it's a problem solver application, go ahead cb...   \n",
      "\n",
      "                           bank  theme  \n",
      "4   Commercial Bank of Ethiopia  Other  \n",
      "6   Commercial Bank of Ethiopia  Other  \n",
      "7   Commercial Bank of Ethiopia  Other  \n",
      "9   Commercial Bank of Ethiopia  Other  \n",
      "10  Commercial Bank of Ethiopia  Other  \n",
      "\n",
      "All done! Reviews with themes saved to C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\reviews_with_themes.csv\n",
      "Theme documentation saved to C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\theme_documentation.md\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set file paths\n",
    "input_path = r\"C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\reviews_with_spacy_keywords.csv\"\n",
    "output_path = r\"C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\reviews_with_themes.csv\"\n",
    "doc_path = r\"C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\theme_documentation.md\"\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading reviews with spaCy keywords...\")\n",
    "try:\n",
    "    df = pd.read_csv(input_path)\n",
    "    print(f\"Success! Loaded {len(df)} reviews.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Oops! Couldn't find 'reviews_with_spacy_keywords.csv' at {input_path}. Please check if Step 6 completed.\")\n",
    "    exit()\n",
    "\n",
    "# Filter out short reviews (< 3 words) to improve accuracy\n",
    "print(\"\\nFiltering out short reviews (less than 3 words)...\")\n",
    "initial_rows = len(df)\n",
    "df['word_count'] = df['review_text'].apply(lambda x: len(str(x).split()))\n",
    "df = df[df['word_count'] >= 3]\n",
    "print(f\"Kept {len(df)} reviews after filtering out {initial_rows - len(df)} short reviews.\")\n",
    "\n",
    "# Define theme assignment function\n",
    "def assign_theme(row):\n",
    "    review = str(row['review_text']).lower()\n",
    "    phrases = row['noun_phrases'] if isinstance(row['noun_phrases'], list) else []\n",
    "    keywords = row['tfidf_keywords'].lower() if isinstance(row['tfidf_keywords'], str) else ''\n",
    "    \n",
    "    # Account Access Issues\n",
    "    if any(k in review for k in ['login', 'access', 'sign in']) or \\\n",
    "       any(p in phrases for p in ['login error', 'access issue']):\n",
    "        return \"Account Access Issues\"\n",
    "    \n",
    "    # App Performance\n",
    "    elif any(k in review for k in ['crash', 'slow', 'bug', 'doesn', 'doesnt']) or \\\n",
    "         any(p in phrases for p in ['app crashes', 'slow transfer', 'bug']) or \\\n",
    "         'crash' in keywords or 'doesn' in keywords:\n",
    "        return \"App Performance\"\n",
    "    \n",
    "    # User Interface\n",
    "    elif any(k in review for k in ['interface', 'ui', 'design']) or \\\n",
    "         any(p in phrases for p in ['user interface', 'good ui', 'nice app']) or \\\n",
    "         'ui' in keywords:\n",
    "        return \"User Interface\"\n",
    "    \n",
    "    # Customer Support\n",
    "    elif any(k in review for k in ['support', 'help', 'service']) or \\\n",
    "         any(p in phrases for p in ['customer support', 'help desk']):\n",
    "        return \"Customer Support\"\n",
    "    \n",
    "    # Feature Requests\n",
    "    elif any(k in review for k in ['feature', 'add', 'update']) or \\\n",
    "         any(p in phrases for p in ['new feature', 'update']) or \\\n",
    "         'update' in keywords:\n",
    "        return \"Feature Requests\"\n",
    "    \n",
    "    # Positive Feedback (catch-all for positive reviews without specific issues)\n",
    "    elif any(p in phrases for p in ['best app', 'good app', 'excellent app']) or \\\n",
    "         keywords in ['best', 'good', 'amazing']:\n",
    "        return \"Positive Feedback\"\n",
    "    \n",
    "    return \"Other\"\n",
    "\n",
    "# Assign themes\n",
    "print(\"\\nAssigning themes to reviews...\")\n",
    "df['theme'] = df.apply(assign_theme, axis=1)\n",
    "\n",
    "# Print theme counts per bank\n",
    "print(\"\\nTheme distribution by bank:\")\n",
    "for bank in df['bank'].unique():\n",
    "    bank_themes = df[df['bank'] == bank]['theme'].value_counts()\n",
    "    print(f\"\\n{bank}:\")\n",
    "    print(bank_themes)\n",
    "\n",
    "# Show a preview of the results\n",
    "print(\"\\nHere's a peek at the reviews with themes:\")\n",
    "print(df[['review_id', 'review_text', 'bank', 'theme']].head())\n",
    "\n",
    "# Save the results\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"\\nAll done! Reviews with themes saved to {output_path}\")\n",
    "\n",
    "documentation = \"\"\"\n",
    "# Theme Grouping Logic\n",
    "Themes were assigned based on keywords and noun phrases from TF-IDF and spaCy, with a rule-based approach to group reviews into 3–5 categories per bank. Short reviews (< 3 words) were filtered to improve accuracy.\n",
    "\n",
    "- **Account Access Issues**: Reviews mentioning 'login', 'access', 'sign in', or phrases like 'login error', 'access issue'.\n",
    "- **App Performance**: Reviews mentioning 'crash', 'slow', 'bug', 'doesn', or phrases like 'app crashes', 'slow transfer'.\n",
    "- **User Interface**: Reviews mentioning 'interface', 'ui', 'design', or phrases like 'user interface', 'good ui', 'nice app'.\n",
    "- **Customer Support**: Reviews mentioning 'support', 'help', 'service', or phrases like 'customer support', 'help desk'.\n",
    "- **Feature Requests**: Reviews mentioning 'feature', 'add', 'update', or phrases like 'new feature', 'update'.\n",
    "- **Positive Feedback**: Positive reviews with phrases like 'best app', 'good app', 'excellent app', or keywords like 'best', 'good', 'amazing', not fitting other categories.\n",
    "- **Other**: Reviews not matching any specific theme.\n",
    "\n",
    "Rules were applied using review text, TF-IDF keywords, and spaCy noun phrases, prioritizing phrases for context. Bank-specific themes were validated by reviewing top keywords/phrases (e.g., 'app crashes' for Bank of Abyssinia).\n",
    "\"\"\"\n",
    "with open(doc_path, 'w') as f:\n",
    "    f.write(documentation)\n",
    "print(f\"Theme documentation saved to {doc_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "038054de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reviews with themes...\n",
      "Success! Loaded 341 reviews.\n",
      "\n",
      "Final dataset summary:\n",
      "Number of reviews: 341\n",
      "Columns: ['review_id', 'review_text', 'sentiment_label', 'sentiment_score', 'theme']\n",
      "\n",
      "Here's a peek at the final output:\n",
      "   review_id                                        review_text  \\\n",
      "0          5                                best app of finance   \n",
      "1          7                               engida kebede fetera   \n",
      "2          8                                   it is not safety   \n",
      "3         10  it is like a childish app make it better the w...   \n",
      "4         11  it's a problem solver application, go ahead cb...   \n",
      "\n",
      "  sentiment_label  sentiment_score  theme  \n",
      "0        positive         0.999650  Other  \n",
      "1        negative         0.839674  Other  \n",
      "2        negative         0.999787  Other  \n",
      "3        negative         0.999796  Other  \n",
      "4        positive         0.999768  Other  \n",
      "\n",
      "All done! Final results saved to C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\final_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set file paths\n",
    "input_path = r\"C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\reviews_with_themes.csv\"\n",
    "output_path = r\"C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\final_reviews.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "print(\"Loading reviews with themes...\")\n",
    "try:\n",
    "    df = pd.read_csv(input_path)\n",
    "    print(f\"Success! Loaded {len(df)} reviews.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Oops! Couldn't find 'reviews_with_themes.csv' at {input_path}. Please check if Step 7 completed.\")\n",
    "    exit()\n",
    "\n",
    "# Select required columns\n",
    "required_columns = ['review_id', 'review_text', 'sentiment_label', 'sentiment_score', 'theme']\n",
    "if not all(col in df.columns for col in required_columns):\n",
    "    print(f\"Error: Dataset needs columns: {required_columns}. Please check 'reviews_with_themes.csv'.\")\n",
    "    exit()\n",
    "\n",
    "final_df = df[required_columns]\n",
    "\n",
    "# Show a summary of the final dataset\n",
    "print(\"\\nFinal dataset summary:\")\n",
    "print(f\"Number of reviews: {len(final_df)}\")\n",
    "print(f\"Columns: {list(final_df.columns)}\")\n",
    "print(\"\\nHere's a peek at the final output:\")\n",
    "print(final_df.head())\n",
    "\n",
    "# Save the final results\n",
    "final_df.to_csv(output_path, index=False)\n",
    "print(f\"\\nAll done! Final results saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395f5e9e",
   "metadata": {},
   "source": [
    "# Document Grouping Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a09b63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking theme documentation...\n",
      "\n",
      "Theme Documentation Content:\n",
      "\n",
      "# Theme Grouping Logic\n",
      "Themes were assigned based on keywords and noun phrases from TF-IDF and spaCy, with a rule-based approach to group reviews into 3–5 categories per bank. Short reviews (< 3 words) were filtered to improve accuracy.\n",
      "\n",
      "- **Account Access Issues**: Reviews mentioning 'login', 'access', 'sign in', or phrases like 'login error', 'access issue'.\n",
      "- **App Performance**: Reviews mentioning 'crash', 'slow', 'bug', 'doesn', or phrases like 'app crashes', 'slow transfer'.\n",
      "- **User Interface**: Reviews mentioning 'interface', 'ui', 'design', or phrases like 'user interface', 'good ui', 'nice app'.\n",
      "- **Customer Support**: Reviews mentioning 'support', 'help', 'service', or phrases like 'customer support', 'help desk'.\n",
      "- **Feature Requests**: Reviews mentioning 'feature', 'add', 'update', or phrases like 'new feature', 'update'.\n",
      "- **Positive Feedback**: Positive reviews with phrases like 'best app', 'good app', 'excellent app', or keywords like 'best', 'good', 'amazing', not fitting other categories.\n",
      "- **Other**: Reviews not matching any specific theme.\n",
      "\n",
      "Rules were applied using review text, TF-IDF keywords, and spaCy noun phrases, prioritizing phrases for context. Bank-specific themes were validated by reviewing top keywords/phrases (e.g., 'app crashes' for Bank of Abyssinia).\n",
      "\n",
      "\n",
      "Task 2 Deliverables Summary:\n",
      "- Final Reviews CSV: C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\final_reviews.csv\n",
      "  - Contains 341 reviews with columns: review_id, review_text, sentiment_label, sentiment_score, theme\n",
      "- Sentiment Aggregation CSV: C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\sentiment_aggregation.csv\n",
      "  - Contains 15 rows with columns: bank, rating, mean_sentiment_score, review_count\n",
      "- Theme Documentation: C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\theme_documentation.md\n",
      "  - Describes theme grouping logic for thematic analysis\n",
      "\n",
      "All done! Task 2 is complete. Check the above files for your final outputs.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Set file paths\n",
    "doc_path = r\"C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\theme_documentation.md\"\n",
    "final_csv_path = r\"C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\final_reviews.csv\"\n",
    "agg_csv_path = r\"C:\\Users\\HP\\10 Acadamy PRojects\\New folder (2)\\Customer-Experience-Analytics\\data\\sentiment_aggregation.csv\"\n",
    "\n",
    "# Verify and print theme documentation\n",
    "print(\"Checking theme documentation...\")\n",
    "try:\n",
    "    with open(doc_path, 'r') as f:\n",
    "        documentation = f.read()\n",
    "    print(\"\\nTheme Documentation Content:\")\n",
    "    print(documentation)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Oops! Couldn't find 'theme_documentation.md' at {doc_path}. Please check if Step 7 completed.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"Error reading theme documentation: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Final summary of deliverables\n",
    "print(\"\\nTask 2 Deliverables Summary:\")\n",
    "print(f\"- Final Reviews CSV: {final_csv_path}\")\n",
    "print(f\"  - Contains 341 reviews with columns: review_id, review_text, sentiment_label, sentiment_score, theme\")\n",
    "print(f\"- Sentiment Aggregation CSV: {agg_csv_path}\")\n",
    "print(f\"  - Contains 15 rows with columns: bank, rating, mean_sentiment_score, review_count\")\n",
    "print(f\"- Theme Documentation: {doc_path}\")\n",
    "print(f\"  - Describes theme grouping logic for thematic analysis\")\n",
    "print(\"\\nAll done! Task 2 is complete. Check the above files for your final outputs.\")\n",
    "\n",
    "# Verify files exist\n",
    "for file_path in [final_csv_path, agg_csv_path, doc_path]:\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"Warning: {file_path} not found. Please ensure previous steps completed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54baf1a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
